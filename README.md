# Source-Free Domain Adaptation with improved Fourier Style Transform
We introduce Source-Free Domain Adaptation with improved Fourier Style Transform for Image Segmentation.


## Requirements
Non-exhaustive list:
* python3.6+
* Pytorch 1.7
* nibabel
* Scipy
* NumPy
* Matplotlib
* Scikit-image
* zsh
* tqdm
* pandas
* scikit-image


## Data scheme
### datasets
├── binary.py								#some useful function for evaluation metrics, like Hausdorff Distance calculation
├── bounds.py								#functions for bounds (for class ratio)
├── calculate_HD.py							#script for HD calculation between data in two folders
├── create_slices.py						#extract images from .nii data
├── data									#folder for datasets 
│   ├── FDA.py								#functions for FST
│   ├── get_similarity.py					#calculate the similarity of labels
│   ├── parse_tfrecords_image.py			#extract images from .tfrecords data
│   ├── remap_values.py						#remap the labels to color map
│   ├── similarity_prostate_cycle.txt		#similarity between source label and target label (generated by original SFDA model) in prostate dataset.
│   ├── similarity_prostate.txt				#similarity between source label and target label (ground truth) in prostate dataset.
│   ├── similarity_whs.txt					#similarity between source label and target label (ground truth) in whs dataset.
│   └── utils								#functions for FST
├── dataloader.py							#dataloader
├── dice3d.py								#function for dice
├── ivd.make								#make file for original SFDA training with ivd dataset
├── layers.py								#layer structure of U-net 
├── losses.py								#loss functions
├── main_sfda.py							#code of training with SFDA architecture 
├── networks.py								#all networks
├── original_prostate.make					#make file for original SFDA training with prostate dataset
├── original_whs.make						#make file for original SFDA training with heart dataset
├── predict									#folder for predict labels
│   └── predict_pros_pure_label				#labels generated with original SFDA model
├── predict_prostate.py						#predict the segmentation labels in prostate image with selected model
├── predict_whs.py							#predict the segmentation labels in heart image with selected model
├── prostate.make							#make file for SFDA + FST training with prostate dataset
├── README.md								#readme
├── results									#folder for trained models
├── scheduler.py							#for loss weight setting
├── sizes									#folder for class ratio information
├── utils.py								#some useful functions for training.
└── whs.make								#make file for SFDA + FST training with heart dataset

the directory structure of dataset should be:  
prostate_source			#the name of dataset
├── train				#folder for training data
│   ├── GT				#folder for ground truth labels of training data
│   └── IMG				#folder for images of training data
└── val					#folder for validation data
    ├── GT				#folder for ground truth labels of validation data
    └── IMG				#folder for images of validation data

The network takes png or nii files as an input. The gt folder contains gray-scale images of the ground-truth, where the gray-scale level is the number of the class (0,1,...K).


### Class-ratio (sizes) prior
The class-ratio prior is estimated from anatomical knowledge for each application. In our implementation, is it estimated for each slice in the target domain training and validation sets. It estimated once, before the start of the adaptation phase, and saved in a csv file. 

Scheme
```
sizes/
    prostate.csv
    whs.csv
    ivd.csv
```
The size csv file should be organized as follows:

| val_ids | dumbpredwtags
| ------------- | ------------- |
| Case00_0.nii | [Estimated_Size_class0, Estimated_Size_class1, ..., Estimated_Size_classk]

Sample from sizes/prostate.csv :

| val_ids  | val_gt_size | dumbpredwtags
| ------------- | ------------- |------------- |
| Case00_0.nii  | [147398.0, 827.0]  | [140225, 6905]
| Case00_1.nii  | [147080.0, 1145.0]  | [140225, 6905]
| Case00_14.nii  | [148225.0, 0.0] | [148225, 0]


## User Guider for running main experiment
Once you have downladed the data and organized it such as in the scheme above, run the main experiment as follows:
```
make -f prostate.make
make -f whs.make
```
This is for SFDA model training
It will first run the source training model, which will be saves in results/cesource, and then the SFDA model, which will be saved in results/sfda.
The settings could be edit by change the settings in the make file

If you want to applied Fourier style transform to source data, just use data/FDA.py script.
After source images with FST have been generated, you can just change the data path in make file for using it to training.


## Modify hyper-parameters for experiment
1. hyper-parameters settings for Fourier style transform:
when use data/FDA.py for FST, set the following parameters:
	beta: set the input of "lb" value, from 0 ~ 1
	target selections: set "select" parameter as "similarity" or "random"
	area selection: set "area" parameter as "full" or "partial"

2. hyper-parameters settings for SFDA training:
when use xxx.make for SFDA training, set the following parameters:
	source data for base segmentation model training: "--target_datase" parameter in line 44 of xxx.make file
	other parameters, such as batch size, learning rate, epoch, could also be found in xxx.make file


## Related Implementation and Dataset
* [Mathilde Bateson](https://github.com/mathilde-b), [Hoel Kervadec](https://github.com/HKervadec), [Jose Dolz](https://github.com/josedolz), Hervé Lombaert, Ismail Ben Ayed. Constrained Domain Adaptation for Image Segmentation. In IEEE Transactions on Medical Imaging, 2021. [[paper]](https://ieeexplore.ieee.org/document/9382339) [[implementation]](https://github.com/mathilde-b/CDA) 
* [Hoel Kervadec](https://github.com/HKervadec), [Jose Dolz](https://github.com/josedolz), Meng Tang, Eric Granger, Yuri Boykov, Ismail Ben Ayed. Constrained-CNN losses for weakly supervised segmentation. In Medical Image Analysis, 2019. [[paper]](https://www.sciencedirect.com/science/article/pii/S1361841518306145?via%3Dihub) [[code]](https://github.com/LIVIAETS/SizeLoss_WSS)
* Prostate Dataset and details: https://liuquande.github.io/SAML/. The SA site dataset was used a target domain, the SB site was used as source domain. For both datasets, we use 20 scans for training, and the remaining 10 scans for validation.
* Heart Dataset and details: We used the preprocessed dataset from Dou et al. : https://github.com/carrenD/Medical-Cross-Modality-Domain-Adaptation. The data is in tfs records, it should be transformed to nii or png before running the makefile.

## Note
The model and code are available for non-commercial research purposes only.
 
